---
title: "Today I Learned"
# autonumber: true
math: true
toc: true
hideBackToTop: false
---

## 2025-10-19
- [How containers work in Modal](https://www.youtube.com/watch?v=SlkEW4C2kd4)
- [Benchmarking inference engines](https://modal.com/llm-almanac/how-to-benchmark)


## 2025-10-15
- [Digging in vLLM](https://www.aleksagordic.com/blog/vllm)
- [How highperf matmul kernels work](https://www.aleksagordic.com/blog/matmul)

## 2025-10-13
- [Matmuls are weird](https://www.thonking.ai/p/strangely-matrix-multiplications)
- [Flash Attention 4](https://modal.com/blog/reverse-engineer-flash-attention-4)
- [Great talk on Nvidia Cutile](https://www.youtube.com/watch?v=uZTtViomW6w)
- [Nvidia Tesla paper](https://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/lindholm08_tesla.pdf)


## 2025-10-12
- [LLM for kernels](https://cognition.ai/blog/kevin-32b)
- [KernelBench](https://scalingintelligence.stanford.edu/blogs/kernelbench/)
- [Accelerating GenAI part 1 / SAM Fast](https://pytorch.org/blog/accelerating-generative-ai/)
- [SAM Fast code](https://github.com/meta-pytorch/segment-anything-fast/tree/main)
- [Accelerating GenAI part 2 / GPT Fast](https://pytorch.org/blog/accelerating-generative-ai/)
- [GPT Fast Code](https://pytorch.org/blog/accelerating-generative-ai/)
- [Way to faster matmul using sparsification](https://developer.nvidia.com/blog/exploiting-ampere-structured-sparsity-with-cusparselt)
- [Recomputation using nerdy algos](https://dev-discuss.pytorch.org/t/min-cut-optimal-recomputation-i-e-activation-checkpointing-with-aotautograd/467)
- [Paper on optimizing data movement in transformers](https://arxiv.org/pdf/2007.00072)
- [TorchDynamo](https://dev-discuss.pytorch.org/t/torchdynamo-an-experiment-in-dynamic-python-bytecode-transformation/361)
- [FlexAttention](https://pytorch.org/blog/flexattention/)
- [Supporting Mixtral in GPT Fast](https://www.thonking.ai/p/short-supporting-mixtral-in-gpt-fast)
- [What Shapes Do Matrix Multiplications Like?](https://www.thonking.ai/p/what-shapes-do-matrix-multiplications)


## 2025-10-11
### Lora serving
- [Dynamically swap LoRA adapters in PEFT](https://huggingface.co/docs/peft/package_reference/hotswap)
- [vLLM LoRA Serving](https://docs.vllm.ai/en/stable/features/lora.html#dynamically-serving-lora-adapters)
- [Multi-LoRA Serving from HF TGI](https://huggingface.co/blog/multi-lora-serving)
- [Multi-LoRA inference server from Predibase](https://github.com/predibase/lorax)
 
### Uncategorized
- [Great paper on Automatic Differentiation](https://arxiv.org/pdf/1502.05767)
- [Distributed Training Lexicon](https://distributedlexicon.com/)
- [All Models Are Wrong: Concepts of Statistical Learning](https://allmodelsarewrong.github.io/)
- [Epic guide on writing CV, statement of purpose, letters of recommendation, specifically for applying to EPFL](https://epic-guide.github.io/applying)
- [Domain Specific Architectures](https://fleetwood.dev/posts/domain-specific-architectures)